"""
ğŸ¯ ì†ë‹´ ê²Œì„ - ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ì†ë‹´ ë‚œì´ë„ ë¶„ì„ í´ë˜ìŠ¤

ì´ ëª¨ë“ˆì€ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ ì†ë‹´ì˜ ë‚œì´ë„ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” í•µì‹¬ í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- ë°ì´í„°ë² ì´ìŠ¤ì˜ ì†ë‹´ì„ 3ë‹¨ê³„ ë‚œì´ë„ë¡œ ë¶„ë¥˜ (1ì , 2ì , 3ì )
- jhgan/ko-sroberta-multitask ëª¨ë¸ ì‚¬ìš©
- ë°°ì¹˜ ì²˜ë¦¬ ë° ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”

ì£¼ìš” ê¸°ëŠ¥:
1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ (proverb_game.proverb í…Œì´ë¸”)
2. AI ëª¨ë¸ì„ í†µí•œ ë‚œì´ë„ ë¶„ì„
3. ë°°ì¹˜ ì²˜ë¦¬ (16ê°œì”© ë¬¶ì–´ì„œ ì²˜ë¦¬)
4. ë¶„ì„ ê²°ê³¼ ìºì‹± ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
5. ì§„í–‰ë¥  í‘œì‹œ (tqdm)

ì‚¬ìš© ì˜ˆì‹œ:
    analyzer = ProverbDifficultyAnalyzer()
    result = analyzer.analyze_proverb_difficulty(proverb_id=1)
    all_results = analyzer.batch_analyze_all_proverbs()
"""

import os
import sys
import time
import traceback
import logging
from typing import Dict, List, Optional, Union, Any, Tuple
from datetime import datetime
import numpy as np

# config ë° database ëª¨ë“ˆ import
try:
    from config import proverb_config
    from database import ProverbDatabase
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    print("í•´ê²° ë°©ë²•: config.py, database.py íŒŒì¼ì´ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
try:
    import torch
    from sentence_transformers import SentenceTransformer
    from transformers import AutoTokenizer, AutoModel
    from tqdm import tqdm
except ImportError as e:
    print(f"âŒ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì‹¤íŒ¨: {e}")
    print("í•´ê²° ë°©ë²•: pip install -r requirements.txt")
    sys.exit(1)


class ProverbDifficultyAnalyzer:
    """
    ğŸ¯ ì†ë‹´ ê²Œì„ - ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ë‚œì´ë„ ë¶„ì„ í´ë˜ìŠ¤
    
    ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ ì†ë‹´ì˜ ë‚œì´ë„ë¥¼ AI ëª¨ë¸ë¡œ ìë™ ë¶„ì„í•©ë‹ˆë‹¤.
    
    íŠ¹ì§•:
    - ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ (proverb_game.proverb í…Œì´ë¸”)
    - jhgan/ko-sroberta-multitask ëª¨ë¸ ì „ìš©
    - 3ë‹¨ê³„ ë‚œì´ë„ ë¶„ë¥˜ (1ì , 2ì , 3ì )
    - ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™” (16ê°œì”© ì²˜ë¦¬)
    - ë¶„ì„ ê²°ê³¼ ìºì‹±ìœ¼ë¡œ ì¤‘ë³µ ë¶„ì„ ë°©ì§€
    """
    
    def __init__(self):
        """
        ğŸ¤– ì†ë‹´ ë‚œì´ë„ ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        1-2ë‹¨ê³„ì—ì„œ ê²€ì¦ëœ ëª¨ë¸ ë¡œë”© ì½”ë“œë¥¼ ì¬ì‚¬ìš©í•˜ê³ 
        ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        """
        self.config = proverb_config
        self.model_name = self.config.MODEL_NAME
        self.device = self.config.DEVICE
        self.cache_dir = self.config.MODEL_CACHE_DIR
        self.batch_size = self.config.BATCH_SIZE_ANALYSIS
        
        # ëª¨ë¸ ê´€ë ¨ ë³€ìˆ˜
        self.sentence_model = None
        self.tokenizer = None
        self.transformer_model = None
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        self.db = None
        
        # ë¶„ì„ ê²°ê³¼ ìºì‹œ
        self.analysis_cache = {} if self.config.ENABLE_CACHING else None
        
        # ë‚œì´ë„ ë¶„ì„ì„ ìœ„í•œ ì°¸ì¡° ì†ë‹´ë“¤
        self.reference_proverbs = self._get_reference_proverbs()
        
        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            "total_analyzed": 0,
            "cache_hits": 0,
            "total_processing_time": 0.0,
            "batch_count": 0
        }
        
        print(f"ğŸ¯ ì†ë‹´ ê²Œì„ ë‚œì´ë„ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
        print(f"ğŸ“ ëª¨ë¸: {self.model_name}")
        print(f"ğŸ’» ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {self.batch_size}")
        print(f"ğŸ’¾ ìºì‹±: {'í™œì„±í™”' if self.config.ENABLE_CACHING else 'ë¹„í™œì„±í™”'}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        if not self._connect_database():
            raise Exception("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
        
        # ëª¨ë¸ ë¡œë”©
        if not self._load_models():
            raise Exception("AI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
        
        print(f"âœ… ì†ë‹´ ë‚œì´ë„ ë¶„ì„ê¸° ì¤€ë¹„ ì™„ë£Œ!")
    
    def _get_reference_proverbs(self) -> Dict[int, List[str]]:
        """
        ğŸ§ª ê° ë‚œì´ë„ë³„ ì°¸ì¡° ì†ë‹´ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Returns:
            Dict[int, List[str]]: ë‚œì´ë„ë³„ ì°¸ì¡° ì†ë‹´ ëª©ë¡
        """
        reference_proverbs = {}
        for level, info in self.config.PROVERB_DIFFICULTY_LEVELS.items():
            reference_proverbs[level] = info['examples']
        return reference_proverbs
    
    def _connect_database(self) -> bool:
        """
        ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ì„¤ì •í•©ë‹ˆë‹¤.
        
        Returns:
            bool: ì—°ê²° ì„±ê³µ ì—¬ë¶€
        """
        try:
            print("â³ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¤‘...")
            self.db = ProverbDatabase()
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            if not self.db.test_connection():
                print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                return False
            
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            if not self.db.check_table_exists():
                print("âŒ proverb í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                return False
            
            proverb_count = self.db.get_proverb_count()
            print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ! (ì†ë‹´ {proverb_count}ê°œ)")
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            return False
    
    def _load_models(self) -> bool:
        """
        ğŸ¤– AI ëª¨ë¸ë“¤ì„ ë¡œë”©í•©ë‹ˆë‹¤.
        
        Returns:
            bool: ëª¨ë¸ ë¡œë”© ì„±ê³µ ì—¬ë¶€
        """
        try:
            print("â³ AI ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(self.cache_dir, exist_ok=True)
            
            # SentenceTransformer ëª¨ë¸ ë¡œë”©
            self.sentence_model = SentenceTransformer(
                self.model_name,
                cache_folder=self.cache_dir,
                device=self.device
            )
            
            # Transformers ëª¨ë¸ ë¡œë”© (í˜¸í™˜ì„±ìš©)
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name,
                cache_dir=self.cache_dir
            )
            
            self.transformer_model = AutoModel.from_pretrained(
                self.model_name,
                cache_dir=self.cache_dir
            ).to(self.device)
            
            print("âœ… ëª¨ë“  AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            print(f"ğŸ“‹ ì—ëŸ¬ ìƒì„¸: {traceback.format_exc()}")
            return False
    
    def _calculate_difficulty_from_embeddings(self, proverb_embedding: np.ndarray) -> Dict[str, float]:
        """
        ğŸ§® ì„ë² ë”© ë²¡í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‚œì´ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            proverb_embedding: ì†ë‹´ì˜ ì„ë² ë”© ë²¡í„°
            
        Returns:
            Dict[str, float]: ê° ë‚œì´ë„ë³„ í™•ë¥  ì ìˆ˜
        """
        try:
            difficulty_scores = {}
            
            for level, reference_list in self.reference_proverbs.items():
                # ì°¸ì¡° ì†ë‹´ë“¤ì˜ ì„ë² ë”© ìƒì„±
                reference_embeddings = self.sentence_model.encode(
                    reference_list, 
                    convert_to_tensor=True
                )
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                from sentence_transformers.util import cos_sim
                similarities = cos_sim(proverb_embedding, reference_embeddings)
                
                # í‰ê·  ìœ ì‚¬ë„ë¥¼ í•´ë‹¹ ë‚œì´ë„ ì ìˆ˜ë¡œ ì‚¬ìš©
                avg_similarity = similarities.mean().item()
                difficulty_scores[level] = max(0.0, avg_similarity)
            
            # ì ìˆ˜ ì •ê·œí™”
            total_score = sum(difficulty_scores.values())
            if total_score > 0:
                for level in difficulty_scores:
                    difficulty_scores[level] /= total_score
            else:
                # ëª¨ë“  ì ìˆ˜ê°€ 0ì¸ ê²½ìš° ê· ë“± ë¶„ë°°
                for level in difficulty_scores:
                    difficulty_scores[level] = 1.0 / len(difficulty_scores)
            
            return difficulty_scores
            
        except Exception as e:
            print(f"âš ï¸ ë‚œì´ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ì—ëŸ¬ ì‹œ ê· ë“± ë¶„ë°°
            num_levels = len(self.reference_proverbs)
            return {level: 1.0/num_levels for level in self.reference_proverbs.keys()}
    
    def analyze_proverb_difficulty(self, proverb_id: Optional[int] = None, 
                                 proverb_text: Optional[str] = None) -> Dict[str, Any]:
        """
        ğŸ¯ ì†ë‹´ì˜ ë‚œì´ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            proverb_id: ë°ì´í„°ë² ì´ìŠ¤ ì†ë‹´ ID (ìš°ì„ ìˆœìœ„)
            proverb_text: ì§ì ‘ ì…ë ¥í•œ ì†ë‹´ í…ìŠ¤íŠ¸
            
        Returns:
            Dict: ë‚œì´ë„ ë¶„ì„ ê²°ê³¼
            {
                "proverb_id": 1,
                "full_proverb": "ê°€ëŠ” ë§ì´ ê³ ì™€ì•¼ ì˜¤ëŠ” ë§ì´ ê³±ë‹¤", 
                "difficulty_level": 2,
                "confidence": 0.85,
                "score": 2,
                "processing_time": 0.15,
                "message": "ë¶„ì„ ì™„ë£Œ"
            }
        """
        start_time = time.time()
        
        try:
            # 1. ì†ë‹´ ë°ì´í„° ì¤€ë¹„
            if proverb_id is not None:
                # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
                proverb_data = self.db.get_proverb_by_id(proverb_id)
                if not proverb_data:
                    return {
                        "proverb_id": proverb_id,
                        "full_proverb": "",
                        "difficulty_level": 0,
                        "confidence": 0.0,
                        "score": 0,
                        "processing_time": time.time() - start_time,
                        "message": f"ì†ë‹´ ID {proverb_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                    }
                
                full_proverb = proverb_data['full_proverb']
                actual_proverb_id = proverb_data['id']
                
            elif proverb_text:
                # ì§ì ‘ ì…ë ¥ëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
                full_proverb = proverb_text.strip()
                actual_proverb_id = None
                
            else:
                return {
                    "proverb_id": None,
                    "full_proverb": "",
                    "difficulty_level": 0,
                    "confidence": 0.0,
                    "score": 0,
                    "processing_time": time.time() - start_time,
                    "message": "ì†ë‹´ ID ë˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”"
                }
            
            # 2. ìºì‹œ í™•ì¸
            cache_key = f"id_{actual_proverb_id}" if actual_proverb_id else f"text_{hash(full_proverb)}"
            
            if self.analysis_cache and cache_key in self.analysis_cache:
                cached_result = self.analysis_cache[cache_key].copy()
                cached_result["processing_time"] = time.time() - start_time
                cached_result["message"] += " (ìºì‹œë¨)"
                self.stats["cache_hits"] += 1
                return cached_result
            
            print(f"ğŸ” ì†ë‹´ ë‚œì´ë„ ë¶„ì„: '{full_proverb}'")
            
            # 3. ì„ë² ë”© ìƒì„±
            proverb_embedding = self.sentence_model.encode([full_proverb], convert_to_tensor=True)[0]
            
            # 4. ë‚œì´ë„ ê³„ì‚°
            difficulty_scores = self._calculate_difficulty_from_embeddings(proverb_embedding)
            
            # 5. ìµœì¢… ë‚œì´ë„ ê²°ì •
            predicted_level = max(difficulty_scores.keys(), key=lambda k: difficulty_scores[k])
            confidence = difficulty_scores[predicted_level]
            
            # 6. ì ìˆ˜ ê³„ì‚°
            level_info = self.config.PROVERB_DIFFICULTY_LEVELS[predicted_level]
            score = level_info["score"]
            
            # 7. ê²°ê³¼ ì •ë¦¬
            processing_time = time.time() - start_time
            
            result = {
                "proverb_id": actual_proverb_id,
                "full_proverb": full_proverb,
                "difficulty_level": predicted_level,
                "confidence": round(confidence, 3),
                "score": score,
                "processing_time": round(processing_time, 3),
                "message": f"ë¶„ì„ ì™„ë£Œ - {level_info['name']} ({score}ì )"
            }
            
            # 8. ìºì‹œ ì €ì¥
            if self.analysis_cache:
                self.analysis_cache[cache_key] = result.copy()
            
            # 9. í†µê³„ ì—…ë°ì´íŠ¸
            self.stats["total_analyzed"] += 1
            self.stats["total_processing_time"] += processing_time
            
            print(f"âœ… ë¶„ì„ ì™„ë£Œ: {level_info['name']} (ì‹ ë¢°ë„: {confidence:.1%}, {processing_time:.3f}ì´ˆ)")
            
            return result
            
        except Exception as e:
            error_message = f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            print(f"âŒ {error_message}")
            
            return {
                "proverb_id": proverb_id,
                "full_proverb": proverb_text or "",
                "difficulty_level": 0,
                "confidence": 0.0,
                "score": 0,
                "processing_time": time.time() - start_time,
                "message": error_message
            }
    
    def batch_analyze_all_proverbs(self) -> List[Dict[str, Any]]:
        """
        ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  ì†ë‹´ì„ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
        
        16ê°œì”© ë¬¶ì–´ì„œ ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ í™•ë³´í•˜ê³ ,
        ì§„í–‰ë¥ ì„ í‘œì‹œí•©ë‹ˆë‹¤.
        
        Returns:
            List[Dict]: ëª¨ë“  ì†ë‹´ì˜ ë¶„ì„ ê²°ê³¼
        """
        print("ğŸ“Š ì „ì²´ ì†ë‹´ ë°°ì¹˜ ë¶„ì„ ì‹œì‘")
        print("=" * 60)
        
        start_time = time.time()
        all_results = []
        
        try:
            # ì „ì²´ ì†ë‹´ ê°œìˆ˜ ì¡°íšŒ
            total_proverbs = self.db.get_proverb_count()
            if total_proverbs == 0:
                print("âŒ ë¶„ì„í•  ì†ë‹´ì´ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            print(f"ğŸ“š ì´ {total_proverbs}ê°œ ì†ë‹´ ë¶„ì„ ì˜ˆì •")
            print(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {self.batch_size}ê°œ")
            
            # ë°°ì¹˜ ê°œìˆ˜ ê³„ì‚°
            total_batches = (total_proverbs + self.batch_size - 1) // self.batch_size
            print(f"ğŸ”„ ì´ {total_batches}ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬")
            
            # ì§„í–‰ë¥  ë°” ì„¤ì •
            with tqdm(total=total_proverbs, desc="ì†ë‹´ ë¶„ì„ ì§„í–‰", unit="ê°œ") as pbar:
                
                for batch_idx in range(total_batches):
                    offset = batch_idx * self.batch_size
                    
                    # ë°°ì¹˜ ë°ì´í„° ì¡°íšŒ
                    batch_proverbs = self.db.get_proverbs_batch(offset, self.batch_size)
                    
                    if not batch_proverbs:
                        break
                    
                    print(f"\n[ë°°ì¹˜ {batch_idx + 1}/{total_batches}] {len(batch_proverbs)}ê°œ ì†ë‹´ ì²˜ë¦¬ ì¤‘...")
                    
                    # ë°°ì¹˜ ë‚´ ê° ì†ë‹´ ë¶„ì„
                    batch_results = []
                    for proverb_data in batch_proverbs:
                        result = self.analyze_proverb_difficulty(proverb_id=proverb_data['id'])
                        batch_results.append(result)
                        pbar.update(1)
                    
                    all_results.extend(batch_results)
                    self.stats["batch_count"] += 1
                    
                    # ë°°ì¹˜ ì™„ë£Œ ì •ë³´
                    success_count = sum(1 for r in batch_results if r['difficulty_level'] > 0)
                    print(f"âœ… ë°°ì¹˜ {batch_idx + 1} ì™„ë£Œ: {success_count}/{len(batch_results)}ê°œ ì„±ê³µ")
            
            # ì „ì²´ ê²°ê³¼ í†µê³„
            total_time = time.time() - start_time
            success_results = [r for r in all_results if r['difficulty_level'] > 0]
            
            print(f"\n" + "=" * 60)
            print(f"ğŸ“ˆ ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ ê²°ê³¼:")
            print(f"  - ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
            print(f"  - ì„±ê³µì ìœ¼ë¡œ ë¶„ì„ëœ ì†ë‹´: {len(success_results)}/{len(all_results)}ê°œ")
            print(f"  - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_time/len(all_results):.3f}ì´ˆ/ê°œ")
            print(f"  - ìºì‹œ ì ì¤‘ë¥ : {self.stats['cache_hits']}/{self.stats['total_analyzed']} ({self.stats['cache_hits']/max(1,self.stats['total_analyzed'])*100:.1f}%)")
            
            # ë‚œì´ë„ë³„ ë¶„í¬
            self._print_difficulty_distribution(success_results)
            
            return all_results
            
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            print(f"ğŸ“‹ ì—ëŸ¬ ìƒì„¸: {traceback.format_exc()}")
            return all_results
    
    def _print_difficulty_distribution(self, results: List[Dict[str, Any]]) -> None:
        """
        ğŸ“Š ë‚œì´ë„ ë¶„í¬ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        
        Args:
            results: ë¶„ì„ ê²°ê³¼ ëª©ë¡
        """
        if not results:
            return
        
        # ë‚œì´ë„ë³„ ê°œìˆ˜ ê³„ì‚°
        difficulty_counts = {1: 0, 2: 0, 3: 0}
        total_score = 0
        
        for result in results:
            level = result.get('difficulty_level', 0)
            if level in difficulty_counts:
                difficulty_counts[level] += 1
                total_score += result.get('score', 0)
        
        total_count = len(results)
        
        print(f"\nğŸ“Š ë‚œì´ë„ ë¶„í¬:")
        for level, count in difficulty_counts.items():
            level_info = self.config.PROVERB_DIFFICULTY_LEVELS[level]
            percentage = (count / total_count) * 100 if total_count > 0 else 0
            print(f"  - {level_info['name']}: {count}ê°œ ({percentage:.1f}%)")
        
        avg_score = total_score / total_count if total_count > 0 else 0
        print(f"\nğŸ¯ í‰ê·  ì ìˆ˜: {avg_score:.2f}ì ")
        print(f"ğŸ† ì´ íšë“ ê°€ëŠ¥ ì ìˆ˜: {total_score}ì ")
    
    def get_analysis_statistics(self) -> Dict[str, Any]:
        """
        ğŸ“ˆ ë¶„ì„ í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            Dict: í†µê³„ ì •ë³´
        """
        return {
            "total_analyzed": self.stats["total_analyzed"],
            "cache_hits": self.stats["cache_hits"],
            "cache_hit_rate": self.stats["cache_hits"] / max(1, self.stats["total_analyzed"]),
            "total_processing_time": self.stats["total_processing_time"],
            "average_processing_time": self.stats["total_processing_time"] / max(1, self.stats["total_analyzed"]),
            "batch_count": self.stats["batch_count"],
            "cache_size": len(self.analysis_cache) if self.analysis_cache else 0,
            "model_info": {
                "name": self.model_name,
                "device": self.device,
                "batch_size": self.batch_size
            }
        }
    
    def clear_cache(self):
        """ğŸ’¾ ë¶„ì„ ê²°ê³¼ ìºì‹œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        if self.analysis_cache:
            cache_size = len(self.analysis_cache)
            self.analysis_cache.clear()
            print(f"ğŸ—‘ï¸ ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ ({cache_size}ê°œ í•­ëª© ì‚­ì œ)")
    
    def close(self):
        """ğŸ”’ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•˜ê³  ì—°ê²°ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."""
        if self.db:
            self.db.close()
        
        # ìºì‹œ ì •ë¦¬
        if self.analysis_cache:
            self.analysis_cache.clear()
        
        print("âœ… ì†ë‹´ ë‚œì´ë„ ë¶„ì„ê¸° ì¢…ë£Œ")


def test_difficulty_analyzer():
    """
    ğŸ§ª ì†ë‹´ ë‚œì´ë„ ë¶„ì„ê¸° ì¢…í•© í…ŒìŠ¤íŠ¸
    """
    print("ğŸ§ª ì†ë‹´ ë‚œì´ë„ ë¶„ì„ê¸° ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    try:
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        analyzer = ProverbDifficultyAnalyzer()
        
        # 1. ê°œë³„ ì†ë‹´ ë¶„ì„ í…ŒìŠ¤íŠ¸
        print(f"\nğŸ” ê°œë³„ ì†ë‹´ ë¶„ì„ í…ŒìŠ¤íŠ¸:")
        print("-" * 40)
        
        # IDë¡œ ë¶„ì„
        result1 = analyzer.analyze_proverb_difficulty(proverb_id=1)
        if result1['difficulty_level'] > 0:
            print(f"âœ… ID ë¶„ì„ ì„±ê³µ:")
            print(f"   ì†ë‹´: {result1['full_proverb']}")
            print(f"   ë‚œì´ë„: {result1['difficulty_level']}ë‹¨ê³„ ({result1['score']}ì )")
            print(f"   ì‹ ë¢°ë„: {result1['confidence']:.1%}")
            print(f"   ì²˜ë¦¬ì‹œê°„: {result1['processing_time']:.3f}ì´ˆ")
        
        # í…ìŠ¤íŠ¸ë¡œ ë¶„ì„
        result2 = analyzer.analyze_proverb_difficulty(proverb_text="í˜¸ë‘ì´ë„ ì œ ë§ í•˜ë©´ ì˜¨ë‹¤")
        if result2['difficulty_level'] > 0:
            print(f"\nâœ… í…ìŠ¤íŠ¸ ë¶„ì„ ì„±ê³µ:")
            print(f"   ì†ë‹´: {result2['full_proverb']}")
            print(f"   ë‚œì´ë„: {result2['difficulty_level']}ë‹¨ê³„ ({result2['score']}ì )")
            print(f"   ì‹ ë¢°ë„: {result2['confidence']:.1%}")
        
        # 2. ë°°ì¹˜ ë¶„ì„ í…ŒìŠ¤íŠ¸ (ì²˜ìŒ 5ê°œë§Œ)
        print(f"\nğŸ“¦ ë°°ì¹˜ ë¶„ì„ í…ŒìŠ¤íŠ¸ (ì²˜ìŒ 5ê°œ ì†ë‹´):")
        print("-" * 40)
        
        # ì„ì‹œë¡œ ë°°ì¹˜ í¬ê¸°ë¥¼ 5ë¡œ ì„¤ì •
        original_batch_size = analyzer.batch_size
        analyzer.batch_size = 5
        
        batch_results = []
        batch_proverbs = analyzer.db.get_proverbs_batch(0, 5)
        
        for proverb_data in batch_proverbs:
            result = analyzer.analyze_proverb_difficulty(proverb_id=proverb_data['id'])
            batch_results.append(result)
        
        # ê²°ê³¼ í…Œì´ë¸” í˜•íƒœë¡œ ì¶œë ¥
        print(f"\nğŸ“‹ ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”:")
        print(f"{'ID':<4} {'ì†ë‹´':<30} {'ë‚œì´ë„':<8} {'ì ìˆ˜':<4} {'ì‹ ë¢°ë„':<8}")
        print("-" * 60)
        
        for result in batch_results:
            if result['difficulty_level'] > 0:
                proverb_short = result['full_proverb'][:25] + "..." if len(result['full_proverb']) > 25 else result['full_proverb']
                level_info = proverb_config.PROVERB_DIFFICULTY_LEVELS[result['difficulty_level']]
                print(f"{result['proverb_id']:<4} {proverb_short:<30} {level_info['name']:<8} {result['score']:<4} {result['confidence']:.1%}")
        
        # ë°°ì¹˜ í¬ê¸° ë³µì›
        analyzer.batch_size = original_batch_size
        
        # 3. í†µê³„ ì •ë³´ ì¶œë ¥
        print(f"\nğŸ“ˆ ë¶„ì„ í†µê³„:")
        print("-" * 40)
        stats = analyzer.get_analysis_statistics()
        print(f"ì´ ë¶„ì„ íšŸìˆ˜: {stats['total_analyzed']}ê°œ")
        print(f"ìºì‹œ ì ì¤‘: {stats['cache_hits']}íšŒ ({stats['cache_hit_rate']:.1%})")
        print(f"í‰ê·  ì²˜ë¦¬ì‹œê°„: {stats['average_processing_time']:.3f}ì´ˆ")
        print(f"ìºì‹œ í¬ê¸°: {stats['cache_size']}ê°œ")
        
        # 4. ì •ë¦¬
        analyzer.close()
        
        print(f"\nâœ… ì†ë‹´ ë‚œì´ë„ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        print(f"ğŸ“‹ ì—ëŸ¬ ìƒì„¸: {traceback.format_exc()}")
        return False


if __name__ == "__main__":
    """
    ğŸš€ ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ í˜¸ì¶œ
    
    ì‹¤í–‰ ë°©ë²•:
        python difficulty_analyzer_new.py
    """
    print("ğŸ¯ ì†ë‹´ ê²Œì„ - ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ë‚œì´ë„ ë¶„ì„ê¸°")
    print("jhgan/ko-sroberta-multitask ëª¨ë¸ ì‚¬ìš©")
    print("3ë‹¨ê³„ ë‚œì´ë„ ë¶„ë¥˜ + ë°°ì¹˜ ì²˜ë¦¬ + ìºì‹±")
    print("ë°ì´í„°ë² ì´ìŠ¤: proverb_game.proverb (root/0000)")
    print()
    
    success = test_difficulty_analyzer()
    sys.exit(0 if success else 1)
